{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60a7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import litellm\n",
    "import requests\n",
    "import time\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b3d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for vLLM to start\n",
      "vLLM started in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "vllm_url = \"http://localhost:8000\"\n",
    "\n",
    "max_wait_seconds = 120\n",
    "print(\"Waiting for vLLM to start\")\n",
    "for sec in range(max_wait_seconds):\n",
    "    try:\n",
    "        if requests.get(f\"{vllm_url}/health\").status_code == 200:\n",
    "            break\n",
    "    except Exception:\n",
    "        pass\n",
    "    time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(\"vLLM server failed to start within the expected time.\")\n",
    "print(f\"vLLM started in {sec} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74bb82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(response):\n",
    "    message = response.choices[0].message\n",
    "    if hasattr(message, \"reasoning_content\"):\n",
    "        print(f\"{colored('Reasoning:', 'red')}\\n{message.reasoning_content}\\n\")\n",
    "    print(f\"{colored('Content:', 'red')}\\n{message.content}\\n\")\n",
    "    print(f\"{colored('Tool Calls:', 'red')}\")\n",
    "    tool_calls = message.tool_calls\n",
    "    if tool_calls:\n",
    "        for call in tool_calls:\n",
    "            print(f\"{call.function.name}: {call.function.arguments} (id: {call.id})\")\n",
    "    else:\n",
    "        print(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9e6b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_keys(d: dict, keys: set[str]) -> dict:\n",
    "    new = {}\n",
    "    for k, v in d.items():\n",
    "        if k in keys:\n",
    "            continue\n",
    "        new[k] = strip_keys(v, keys) if isinstance(v, dict) else v\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74dc44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_func_schema(name: str, description: str, params: BaseModel) -> dict:\n",
    "    param_schema = strip_keys(params.model_json_schema(), {\"title\"})\n",
    "    func_schema = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                **param_schema,\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        },\n",
    "        \"strict\": True,\n",
    "    }\n",
    "    return func_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45785eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"description\": \"Get the current weather for the location(s)\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"locations\": {\n",
      "            \"description\": \"List of locations for which to get the current weather\",\n",
      "            \"items\": {\n",
      "              \"type\": \"string\"\n",
      "            },\n",
      "            \"type\": \"array\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"locations\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      }\n",
      "    },\n",
      "    \"strict\": true\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"reply\",\n",
      "      \"description\": \"Reply to the user with a free-form message\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"msg\": {\n",
      "            \"description\": \"The free-form reply message to the user\",\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"msg\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      }\n",
      "    },\n",
      "    \"strict\": true\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "class GetWeatherFuncParams(BaseModel):\n",
    "    # location: str = Field(..., description=\"Location for which to get the weather\")\n",
    "    locations: list[str] = Field(\n",
    "        ..., description=\"List of locations for which to get the current weather\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ReplyFuncParams(BaseModel):\n",
    "    msg: str = Field(..., description=\"The free-form reply message to the user\")\n",
    "\n",
    "\n",
    "get_weather_func_schema = make_func_schema(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the current weather for the location(s)\",\n",
    "    params=GetWeatherFuncParams,\n",
    ")\n",
    "\n",
    "reply_func_schema = make_func_schema(\n",
    "    name=\"reply\",\n",
    "    description=\"Reply to the user with a free-form message\",\n",
    "    params=ReplyFuncParams,\n",
    ")\n",
    "\n",
    "tools = [get_weather_func_schema, reply_func_schema]\n",
    "\n",
    "print(json.dumps(tools, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9048b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant. Don't overthink your answers. Reason concisely and minimally.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in 10 cities in the world? Pick any cities you like.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a04c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mReasoning:\u001b[0m\n",
      "Okay, the user is asking for the weather in 10 cities around the world. Let me check the available tools. There's the get_weather function that takes a list of locations. The user says to pick any cities, so I need to choose 10. Let me think of some major cities: New York, London, Tokyo, Paris, Sydney, Mumbai, Rio de Janeiro, Cape Town, Moscow, and Dubai. Wait, I should make sure they're all distinct and well-known. Let me confirm those are correct. New York, London, Tokyo, Paris, Sydney, Mumbai, Rio, Cape Town, Moscow, Dubai. Yep, that's 10. Now, I need to call get_weather with these locations. The function requires an array of strings, so I'll structure the arguments as a list. Let me double-check the parameters. The function's required parameter is \"locations\" as an array. So the tool call should have \"locations\" with those 10 cities. I'll make sure to format it correctly in JSON. No need for the reply function yet since the user wants the weather data. Alright, let's generate the tool call.\n",
      "\n",
      "\n",
      "\u001b[31mContent:\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[31mTool Calls:\u001b[0m\n",
      "get_weather: {\"locations\": [\"New York\", \"London\", \"Tokyo\", \"Paris\", \"Sydney\", \"Mumbai\", \"Rio de Janeiro\", \"Cape Town\", \"Moscow\", \"Dubai\"]} (id: chatcmpl-tool-8202c2e2b2359bdf)\n"
     ]
    }
   ],
   "source": [
    "# litellm.drop_params = True  # Drop params incompatible with the model\n",
    "\n",
    "response = litellm.completion(\n",
    "    # model=\"openai/gpt-5-mini\",\n",
    "    model=\"openai/Qwen3-30B-A3B-Thinking-2507-FP8\",\n",
    "    api_base=f\"{vllm_url}/v1\",\n",
    "    messages=conversation,\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\",\n",
    ")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436a1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool-calling-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
