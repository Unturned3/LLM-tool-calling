{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b60a7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import litellm\n",
    "import requests\n",
    "import time\n",
    "from termcolor import colored\n",
    "import dotenv\n",
    "\n",
    "from openai_function_calling import FunctionInferrer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2a3d9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b3d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for vLLM to start\n",
      "vLLM started in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "vllm_url = \"http://localhost:8005\"\n",
    "\n",
    "max_wait_seconds = 120\n",
    "print(\"Waiting for vLLM to start\")\n",
    "for sec in range(max_wait_seconds):\n",
    "    try:\n",
    "        if requests.get(f\"{vllm_url}/health\").status_code == 200:\n",
    "            break\n",
    "    except Exception:\n",
    "        pass\n",
    "    time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(\"vLLM server failed to start within the expected time.\")\n",
    "print(f\"vLLM started in {sec} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74bb82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(response):\n",
    "    message = response.choices[0].message\n",
    "    if hasattr(message, \"reasoning_content\"):\n",
    "        print(f\"{colored('Reasoning:', 'red')}\\n{message.reasoning_content}\\n\")\n",
    "    print(f\"{colored('Content:', 'red')}\\n{message.content}\\n\")\n",
    "    print(f\"{colored('Tool Calls:', 'red')}\")\n",
    "    tool_calls = message.tool_calls\n",
    "    if tool_calls:\n",
    "        for call in tool_calls:\n",
    "            print(f\"{call.function.name}: {call.function.arguments} (id: {call.id})\")\n",
    "    else:\n",
    "        print(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e6b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_keys(d: dict, keys: set[str]) -> dict:\n",
    "    new = {}\n",
    "    for k, v in d.items():\n",
    "        if k in keys:\n",
    "            continue\n",
    "        new[k] = strip_keys(v, keys) if isinstance(v, dict) else v\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74dc44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_func_schema(name: str, description: str, params: BaseModel) -> dict:\n",
    "    param_schema = strip_keys(params.model_json_schema(), {\"title\"})\n",
    "    func_schema = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                **param_schema,\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        },\n",
    "        \"strict\": True,\n",
    "    }\n",
    "    return func_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45785eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"description\": \"Get the current weather for the location(s)\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"locations\": {\n",
      "            \"description\": \"List of locations for which to get the current weather\",\n",
      "            \"items\": {\n",
      "              \"type\": \"string\"\n",
      "            },\n",
      "            \"type\": \"array\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"locations\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      }\n",
      "    },\n",
      "    \"strict\": true\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"reply\",\n",
      "      \"description\": \"Reply to the user with a free-form message\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"msg\": {\n",
      "            \"description\": \"The free-form reply message to the user\",\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"msg\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      }\n",
      "    },\n",
      "    \"strict\": true\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "class GetWeatherFuncParams(BaseModel):\n",
    "    # location: str = Field(..., description=\"Location for which to get the weather\")\n",
    "    locations: list[str] = Field(\n",
    "        ..., description=\"List of locations for which to get the current weather\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ReplyFuncParams(BaseModel):\n",
    "    msg: str = Field(..., description=\"The free-form reply message to the user\")\n",
    "\n",
    "\n",
    "get_weather_func_schema = make_func_schema(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the current weather for the location(s)\",\n",
    "    params=GetWeatherFuncParams,\n",
    ")\n",
    "\n",
    "reply_func_schema = make_func_schema(\n",
    "    name=\"reply\",\n",
    "    description=\"Reply to the user with a free-form message\",\n",
    "    params=ReplyFuncParams,\n",
    ")\n",
    "\n",
    "tools = [get_weather_func_schema, reply_func_schema]\n",
    "\n",
    "print(json.dumps(tools, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9048b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant. Don't overthink your answers. Reason concisely and minimally.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in 10 cities in the world? Pick any cities you like.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29b9aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather for the location(s)\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"locations\": {\n",
    "                        # \"description\": \"List of locations for which to get the current weather\",\n",
    "                        \"items\": {\"type\": \"string\"},\n",
    "                        \"type\": \"array\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"locations\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        },\n",
    "        \"strict\": True,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a04c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mContent:\u001b[0m\n",
      "None\n",
      "\n",
      "\u001b[31mTool Calls:\u001b[0m\n",
      "get_weather: {\"locations\":[\"New York, USA\",\"London, UK\",\"Tokyo, Japan\",\"Sydney, Australia\",\"Cairo, Egypt\",\"Rio de Janeiro, Brazil\",\"Moscow, Russia\",\"Mumbai, India\",\"Cape Town, South Africa\",\"Toronto, Canada\"]} (id: call_F5zHsfLfnGS44VMZS1Pr57mb)\n"
     ]
    }
   ],
   "source": [
    "# litellm.drop_params = True  # Drop params incompatible with the model\n",
    "\n",
    "model = \"openai/gpt-5-mini\"\n",
    "# model=\"openai/Qwen3-30B-A3B-Thinking-2507-FP8\"\n",
    "# model = \"openai/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "response = litellm.completion(\n",
    "    model=model,\n",
    "    api_base=f\"{vllm_url}/v1\" if \"gpt\" not in model else None,\n",
    "    messages=conversation,\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\",\n",
    ")\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9b23336",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = json.loads(response.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66abe220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York, USA',\n",
       " 'London, UK',\n",
       " 'Tokyo, Japan',\n",
       " 'Sydney, Australia',\n",
       " 'Cairo, Egypt',\n",
       " 'Rio de Janeiro, Brazil',\n",
       " 'Moscow, Russia',\n",
       " 'Mumbai, India',\n",
       " 'Cape Town, South Africa',\n",
       " 'Toronto, Canada']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[\"locations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a436a1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"get_weather\",\n",
      "  \"description\": \"Get the current weather for the given locations in Celsius. Returns a list of float.\",\n",
      "  \"parameters\": {\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "      \"locations\": {\n",
      "        \"type\": \"array\",\n",
      "        \"description\": \"A list of location names.\",\n",
      "        \"items\": {\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"use_cache\": {\n",
      "        \"type\": \"boolean\",\n",
      "        \"description\": \"Whether to use cached results. Defaults to True.\"\n",
      "      }\n",
      "    },\n",
      "    \"required\": [\n",
      "      \"locations\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_weather(locations: list[str], use_cache: bool = True) -> list[float]:\n",
    "    \"\"\"\n",
    "    Get the current weather for the given locations in Celsius. Returns a list of float.\n",
    "    Args:\n",
    "        locations (list[str]): A list of location names.\n",
    "        use_cache (bool, optional): Whether to use cached results. Defaults to True.\n",
    "    \"\"\"\n",
    "    return [25.4] * len(locations)  # Dummy implementation\n",
    "\n",
    "\n",
    "schema = FunctionInferrer.infer_from_function_reference(get_weather)\n",
    "print(json.dumps(schema.to_json_schema(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool-calling-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
